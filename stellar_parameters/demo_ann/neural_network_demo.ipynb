{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ad621b-8028-4b3f-96ad-b9aff1b91d0c",
   "metadata": {},
   "source": [
    "# Step-by-step: Write your own neural networks with `pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61b0a8-88c2-4a8f-b58c-6bf5246388ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "import joblib\n",
    "flux, flux_err,labels = joblib.load(\"data.bz2\")\n",
    "flux[~np.isfinite(flux)] = 0\n",
    "flux[flux > 2] = 2\n",
    "flux[flux < 0] = 0\n",
    "labels[:,0] /= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458c6f1-a6a3-4c1c-8a4c-a6a9da7d2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(labels[:, 0], labels[:, 1], s=10, c=labels[:, 2], cmap=plt.cm.jet, edgecolor=\"k\", lw=.1)\n",
    "plt.colorbar()\n",
    "plt.xlim(12, 3.5)\n",
    "plt.ylim(5.5, 0.5)\n",
    "plt.xlabel(\"Teff/K\")\n",
    "plt.ylabel(\"logg/dex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953c731-99f6-4a1f-aec1-91057e0f00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134a182-8de2-41c9-b048-bd107605481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "flux_tensor = torch.from_numpy(flux.astype(np.float32))\n",
    "flux_err_tensor = torch.from_numpy(flux_err.astype(np.float32))\n",
    "labels_tensor = torch.from_numpy(labels.astype(np.float32))\n",
    "flux_tensor.size(), labels_tensor.size(), flux_tensor.dtype, labels_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec898d-ddaf-4f78-94aa-8bedffb33282",
   "metadata": {},
   "source": [
    "## data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff660c24-963c-468d-9817-e9fe7c4f6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(*args, f_train=0.7, batch_size=50, train=True):\n",
    "    n_data = len(args[0])\n",
    "    n_train = int(n_data * f_train)\n",
    "    \n",
    "    # shuffle data\n",
    "    index = np.arange(0, n_data, dtype=int)\n",
    "    # np.random.seed(0)\n",
    "    np.random.shuffle(index)\n",
    "        \n",
    "    if train:\n",
    "        # get training set\n",
    "        for i in range(0, n_train, batch_size):\n",
    "            yield (_[index[i:min(i + batch_size, n_train)]] for _ in args)\n",
    "    else:\n",
    "        # get test set\n",
    "        for i in range(n_train, n_data, batch_size):\n",
    "            yield (_[index[i:min(i + batch_size, n_data)]] for _ in args)\n",
    "\n",
    "print(\"get training set\")    \n",
    "for x, y in data_loader(flux_tensor, labels_tensor, train=True):\n",
    "    print(x.size(), y.size())\n",
    "    \n",
    "print(\"get training set\")    \n",
    "for x, y in data_loader(flux_tensor, labels_tensor, train=False):\n",
    "    print(x.size(), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b88e0-4efa-453c-a93c-f7936d958691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "NPIX = 1500\n",
    "NLBL = 3\n",
    "BS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91663a-931a-4175-b7d4-e306514755e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Backward model (Multi-Layer Perceptron)\n",
    "\n",
    "$(T_\\mathrm{eff}, \\log{g}, \\mathrm{[Fe/H]}) = f(F_\\lambda)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e160c-d237-4e9e-9219-7635daefbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_features=NPIX),\n",
    "    nn.Linear(in_features=NPIX, out_features=100),\n",
    "    nn.BatchNorm1d(num_features=100),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=100, out_features=3),\n",
    ")\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65321d59-6fd5-4cc5-b4ae-ed2141857124",
   "metadata": {},
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54343c4-d923-4ef5-8f4c-74ddc7c379cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, lr=1e-4, n_epoch=100, batch_size=50, step=10):\n",
    "    training_loss_history = []\n",
    "    test_loss_history = []\n",
    "    \n",
    "    loss_fn = nn.L1Loss()\n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    for i_epoch in range(n_epoch):\n",
    "        # in each epoch\n",
    "        training_data_counts = 0\n",
    "        training_loss_value = 0\n",
    "        for batch_X, batch_y in data_loader(*data, batch_size=batch_size, train=True):\n",
    "            # for each batch\n",
    "            model.zero_grad()\n",
    "            batch_y_pred = model(batch_X)\n",
    "            batch_loss = loss_fn(batch_y_pred, batch_y)\n",
    "            training_data_counts += len(batch_X)\n",
    "            training_loss_value += batch_loss.detach() * training_data_counts\n",
    "            # print(batch_loss.detach())\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(batch_loss)\n",
    "        training_loss_history.append(training_loss_value / training_data_counts)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_data_counts = 0\n",
    "            test_loss_value = 0\n",
    "            for batch_X, batch_y in data_loader(*data, batch_size=batch_size, train=False):\n",
    "                batch_y_pred = model(batch_X)\n",
    "                batch_loss = loss_fn(batch_y_pred, batch_y)\n",
    "                test_data_counts += len(batch_X)\n",
    "                test_loss_value += batch_loss.detach() * test_data_counts\n",
    "            test_loss_history.append(test_loss_value / test_data_counts)\n",
    "        if i_epoch % step == 0:\n",
    "            print(f\"Epoch {i_epoch:05d}: training loss = {training_loss_history[-1]}, test loss = {test_loss_history[-1]}\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(np.log10(training_loss_history), label=\"training loss\")\n",
    "    plt.plot(np.log10(test_loss_history), label=\"test loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"log10(loss)\")\n",
    "    return training_loss_history, test_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16ccc9-b185-4578-8540-2b72f14c2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = train(data=(flux_tensor, labels_tensor), model=mlp, n_epoch=500, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d4389-1324-459f-9fa0-f7d43cf1338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a spectrum\n",
    "mlp.eval()\n",
    "flux_tensor[:5], mlp(flux_tensor[:5]), labels_tensor[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70606815-667d-478f-a501-10bcdd9d0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_labels(x1, x2):\n",
    "    ndim = x1.shape[1]\n",
    "    fig, axs = plt.subplots(1, ndim, figsize=(3*ndim, 3))\n",
    "    for idim in range(ndim):\n",
    "        axs[idim].plot(x1[:, idim], x2[:, idim], '.')\n",
    "        _xlim = axs[idim].get_xlim()\n",
    "        _ylim = axs[idim].get_ylim()\n",
    "        _lim = min(_xlim[0], _ylim[0]), min(_xlim[1], _ylim[1])\n",
    "        axs[idim].set_xlim(_lim)\n",
    "        axs[idim].set_ylim(_lim)\n",
    "        axs[idim].plot(_lim, _lim, 'k--')\n",
    "        axs[idim].set_xlabel(\"truth\")\n",
    "        axs[idim].set_ylabel(\"prediction\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "compare_labels(labels_tensor, mlp(flux_tensor).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2dc7e-f3fa-4f7e-b5c0-d06a14b83c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "326dc875-e9eb-4ec4-be6e-137f86c1f32c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Backward model (Convolutional neural network, CNN)\n",
    "\n",
    "$(T_\\mathrm{eff}, \\log{g}, \\mathrm{[Fe/H]}) = f(F_\\lambda)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0218bb9-e42d-4493-ac12-9732b0d23c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Sequential(\n",
    "    \n",
    ")\n",
    "print(cnn)\n",
    "cnn(torch.rand(size=(10, 1, 1500))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bcebd-e5d4-4850-8e74-898f67d716d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = train(data=(flux_tensor.unsqueeze(dim=1), labels_tensor), model=cnn, n_epoch=500, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19061c-2553-4093-836f-f9b52c2ce46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_labels(labels_tensor, cnn(flux_tensor.unsqueeze(dim=1)).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc4536-16d0-4cd3-a682-48d9329f2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_tensor.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493c035-ce47-4abb-966e-e61089a24311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e893b72-b8de-4c4b-bcf4-e05ca560ad47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Backward model (MLP)\n",
    "\n",
    "$F_\\lambda = f(T_\\mathrm{eff}, \\log{g}, \\mathrm{[Fe/H]})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64638275-4593-43f6-96b1-7e30b6e0a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_back = nn.Sequential(\n",
    "    \n",
    ")\n",
    "mlp_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f13dc-6e9b-446f-8e41-35c3e4082076",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = train(data=(labels_tensor, flux_tensor), model=mlp_back, n_epoch=5000, step=100)\n",
    "mlp_back.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71ce4c-8ef7-43b5-89b7-bc847739991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "ofst = 0.5\n",
    "plt.plot(flux[::100].T+ np.arange(10)[None, :]*ofst, color=\"k\")\n",
    "plt.plot(mlp_back(labels_tensor[::100]).detach().T + np.arange(10)[None, :]*ofst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afd106-7bbe-4eb0-a1ac-54df9ccf845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.median(mlp_back(labels_tensor[:10]) - flux_tensor[:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d459f9b-e46b-44b3-89b9-4c559b1f55ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90526dc0-5653-4a03-9d3d-df045d42a33a",
   "metadata": {},
   "source": [
    "# 4. Autoencoder (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240fc03c-4fd2-4555-b355-8d7becf7df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7244080-130d-4c98-8dad-1b2cad26f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AE()\n",
    "print(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79da9b-d646-41ea-ba8b-5777025bbe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to init bias in the last layer\n",
    "ae.decoder[-1].bias.data = torch.median(flux_tensor, axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aecde0-5b2a-49fd-8941-5de81a559691",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.median(ae.decoder[-1].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d646182-6337-4b27-ac31-46b50bbbd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = train(data=(flux_tensor, flux_tensor), model=ae, n_epoch=5000, step=100)\n",
    "ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24ef64-7156-4559-9f5f-0bcd21d7d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "ofst = 0.5\n",
    "plt.plot(flux[::100].T+ np.arange(10)[None, :]*ofst, color=\"k\")\n",
    "plt.plot(ae(flux_tensor[::100]).detach().T + np.arange(10)[None, :]*ofst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c40fb-336f-441e-8126-78ea67abbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b98f9-5b41-4053-9bb7-2f27d2834c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.encoder(torch.rand(size=(10, 1500))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6389a-2be8-4c91-95a0-25248ab76b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(*ae.encoder(flux_tensor).detach().T, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ed7f7-9473-4753-9a4f-bafc2577a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 2.5))\n",
    "for idim in range(3):\n",
    "    h = axs[idim].scatter(*ae.encoder(flux_tensor).detach().T, s=10, c=labels[:,idim], cmap=plt.cm.jet)\n",
    "    plt.colorbar(mappable=h, ax=axs[idim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27902c-ee4a-4801-81cb-6f3bc116e63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
